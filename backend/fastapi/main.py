from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware 
import uvicorn
import asyncio
import cv2
import time
import numpy as np 
import subprocess 
import shlex 
import json
import os
import torch
from typing import List, Dict, Any, Tuple, Optional
from ultralytics import YOLO 
from contextlib import asynccontextmanager # â˜…ì¶”ê°€: lifespan ì‚¬ìš©ì„ ìœ„í•œ ëª¨ë“ˆ


# ====================================================================
# â˜…â˜…â˜… 0. í•µì‹¬ ì„¤ì • ë° ìƒìˆ˜ â˜…â˜…â˜…
# ====================================================================

OUT_W = 1024  # FFmpegì˜ ì¶œë ¥ í”„ë ˆì„ ë„ˆë¹„ (í”½ì…€). ë¶„ì„ ì„±ëŠ¥ê³¼ í™”ì§ˆì˜ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤.
OUT_H = 768   # FFmpegì˜ ì¶œë ¥ í”„ë ˆì„ ë†’ì´ (í”½ì…€).
YOLO_MODEL_PATH = "beach_yolo.pt" # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ/ì´ë¦„.
YOLO_CONF_THRESHOLD = 0.44   # YOLO íƒì§€ ê²°ê³¼ì˜ ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’. 0.0 ~ 1.0 ì‚¬ì´ ê°’.
DET_EVERY_FRAMES = 1 # â˜…ì„±ëŠ¥ ìµœì í™”: YOLO ì¶”ë¡ ì„ ëª‡ í”„ë ˆì„ë§ˆë‹¤ ì‹¤í–‰í• ì§€ ê²°ì •í•©ë‹ˆë‹¤. 
FRAME_SIZE = OUT_W * OUT_H * 3 # FFmpegìœ¼ë¡œë¶€í„° ì½ì–´ì˜¬ RAW BGR (3ì±„ë„) í”„ë ˆì„ì˜ ì´ ë°”ì´íŠ¸ í¬ê¸°.

YOUTUBE_URL_TO_FETCH = ""

MIN_MOTION_AREA = 500 # GMMì´ ì›€ì§ì„ìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ í”½ì…€ ì˜ì—­ í¬ê¸°.
MAX_MOTION_AREA = 5000

USE_GMM = False

# ì „ì—­ ìƒíƒœ ë³€ìˆ˜ (AIStreamServer í´ë˜ìŠ¤ì—ì„œ ì´ˆê¸°í™”ë¨)
VIDEO_SOURCES: List[Tuple[str, str]] = []
yolo_model = None
gmm_models = {}
frame_counters = {}

SEND_TIMEOUT = 0.08  # 80ms

CAMERA_CONFIG: Dict[str, Dict[str, Any]] = {
    "CAM1": 
    {
        "label": "ì´í˜¸í…Œìš°",
        "url": "http://211.114.96.121:1935/jejusi7/11-30T.stream/playlist.m3u8",
        "roi_px": [(0, 768), (1024, 400), (1024, 768), (0, 768)],       # yolo, gmm ê´€ì‹¬ ì˜ì—­ ì„¤ì • // ì „ì²´ í•´ìƒë„ ë³€ê²½ ì‹œ ì´ê²ƒë„ ë³€ê²½í•´ì•¼ í•¨                    # âœ³âœ³ CAM(ìŠ¤íŠ¸ë¦¼)ë³„ í•´ì•ˆì„  ì„¤ì • âœ³âœ³
        "safe_zone_px": [(0, 550), (1024, 550), (1024, 768), (0, 768),],                       
    },
    "CAM2": 
    {
        "label": "ì¤‘ë¬¸",
        "url": "http://59.8.86.94:8080/media/api/v1/hls/vurix/192871/100010/0/1/1.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],     
        "safe_zone_px": [(350, 0), (350, 768), (1024, 768), (1024, 0),],                           
    },
    "CAM3": 
    {
        "label": "í•¨ë•",
        "url": "http://211.114.96.121:1935/jejusi6/11-19.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],     
        "safe_zone_px": [(0, 510), (1024, 350), (1024, 768), (0, 768),],                       
    },
    "CAM4": 
    {
        "label": "ì›”ì •ë¦¬",
        "url": "http://211.114.96.121:1935/jejusi7/11-21.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],     
        "safe_zone_px": [(0, 290), (1024, 220), (1024, 768), (0, 768),],                         
    },
    "CAM5": 
    {
        "label": "ì• ì›” í•˜ê·€ ê°€ë¬¸ë™ í¬êµ¬",
        "url": "http://211.114.96.121:1935/jejusi6/11-15.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],      
        "safe_zone_px": [(600, 768), (500, 200), (600, 190), (1024, 700),],                        
    },
    "CAM6": 
    {
        "label": "ê¹€ë…•ë¦¬ í¬êµ¬",
        "url": "http://211.114.96.121:1935/jejusi6/11-20.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],       
        "safe_zone_px": [(100, 0), (1024, 600), (1024, 768), (0, 768),],                    
    },
    "CAM7": 
    {
        "label": "ìˆ˜ë§ˆ í¬êµ¬",
        "url": "http://211.34.191.215:1935/live/1-76.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],           
        "safe_zone_px": [(350, 768), (1024, 450), (1024, 768), (0, 768),],                   
    },
    "CAM8": 
    {
        "label": "ì• ì›” í•˜ê·€ ê°€ë¬¸ë™ í¬êµ¬",
        "url": "",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],       
        "safe_zone_px": [(0, 290), (1024, 400), (1024, 768), (1024, 767),],                        
    },

}


# ====================================================================
# â˜…â˜…â˜… Helper í•¨ìˆ˜: Streamlink ë° GMM ë¡œì§ â˜…â˜…â˜…
# ====================================================================

def get_ytdlp_url(youtube_url: str) -> Optional[str]:
    """YouTube í˜ì´ì§€ì—ì„œ FFmpegì´ ë°”ë¡œ ì½ì„ m3u8 ì¬ìƒ URLë§Œ ì¶”ì¶œ."""
    try:
        # 1) m3u8 ì§ì¶œ (í•œ ì¤„ ì¶œë ¥)
        cmd = f'yt-dlp -g -f "best[protocol^=m3u8]/b[ext=m3u8]" {youtube_url}'
        out = subprocess.check_output(shlex.split(cmd), text=True, stderr=subprocess.STDOUT, timeout=20)
        url = out.strip().splitlines()[-1] if out.strip() else None
        if url and ".m3u8" in url:
            return url
    except Exception as e:
        print(f"[YTDLP] m3u8 ì§ì¶œ ì‹¤íŒ¨: {e}")

    try:
        # 2) í´ë°±: JSONì—ì„œ m3u8 í¬ë§·ë§Œ ê³¨ë¼ ì¶”ì¶œ
        cmd = f'yt-dlp --dump-json --no-warnings -f "bv*+ba/best" {youtube_url}'
        out = subprocess.check_output(shlex.split(cmd), text=True, stderr=subprocess.STDOUT, timeout=25)
        info = json.loads(out)
        for f in (info.get("formats") or []):
            u = f.get("url", "")
            if u and (".m3u8" in u or "m3u8" in (f.get("ext","") + f.get("protocol",""))):
                return u
    except Exception as e:
        print(f"[YTDLP] JSON í´ë°± ì‹¤íŒ¨: {e}")

    return None

def is_overlap(box1, box2):
    """ë‘ ë°•ìŠ¤ê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸ (GMM ë³´ì™„ íƒì§€ì—ì„œ ì¤‘ë³µ íƒì§€ ë°©ì§€ìš©)"""
    x1_min, y1_min, x1_max, y1_max = box1
    x2_min, y2_min, x2_max, y2_max = box2
    
    if (x1_max < x2_min or x1_min > x2_max or
        y1_max < y2_min or y1_min > y2_max):
        return False
    return True

def build_roi_mask_px(w:int, h:int, pts_px):
    """í”½ì…€ ë‹¤ê°í˜• pts_pxë¡œ ROI ë§ˆìŠ¤í¬ ìƒì„± (í°=ê´€ì‹¬, ê²€ì •=ë¬´ì‹œ)"""
    if not pts_px:
        return None
    m = np.zeros((h, w), np.uint8)
    cv2.fillPoly(m, [np.array(pts_px, np.int32)], 255)
    return m

# ====================================================================
# â˜…â˜…â˜… 1. AI ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ í´ë˜ìŠ¤ ì •ì˜ â˜…â˜…â˜…
# ====================================================================

class AIStreamServer:
    def __init__(self):  # ê°ì²´ ë§Œë“¤ ë•Œ ê¸°ë³¸ ë³€ìˆ˜ ì¤€ë¹„ 
        self.yolo_model = None
        self.gmm_models = {}
        self.frame_counters = {}
        self.video_sources: List[Tuple[str, str]] = []
        self.roi_masks = {}  # â˜…ì¶”ê°€: ROI ë§ˆìŠ¤í¬ ìºì‹œ

    async def initialize(self): # ê¸°ë³¸ ì •ë³´ ì„¸íŒ…
        """ì„œë²„ ì‹œì‘ ì‹œ Streamlink í˜¸ì¶œ ë° ëª¨ë“  ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤."""
        global yolo_model, gmm_models, frame_counters, VIDEO_SOURCES
        
        print("ì„œë²„ ì´ˆê¸°í™” ë¡œì§ ì‹¤í–‰: Streamlink ë° ëª¨ë¸ ë¡œë“œ ì‹œì‘...")

        # stream2_youtube_url = get_ytdlp_url(YOUTUBE_URL_TO_FETCH)
        
        self.video_sources = [
            (cam_id, cfg["url"]) for cam_id, cfg in CAMERA_CONFIG.items()
        ]
        
        try:
            self.yolo_model = YOLO(os.path.join("/server/app/yolopt", YOLO_MODEL_PATH))
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.yolo_model.to(device)
            self.yolo_device = device
            self.yolo_half = (device == "cuda")
            print(f"YOLO model loaded successfully.")
        except Exception as e:
            self.yolo_model = None
            
        self.gmm_models = {} if not USE_GMM else {
            name: cv2.createBackgroundSubtractorMOG2(history=1200, varThreshold=25, detectShadows=False)
            for name, _ in self.video_sources
        }
        self.frame_counters = {cam_id: 0 for cam_id in CAMERA_CONFIG.keys()}

        # â˜…ì¶”ê°€: ROI ë§ˆìŠ¤í¬ ìƒì„± (í•´ìƒë„ ê¸°ì¤€ í•œ ë²ˆë§Œ)
        self.roi_masks = {
            cam_id: build_roi_mask_px(OUT_W, OUT_H, cfg["roi_px"])
            for cam_id, cfg in CAMERA_CONFIG.items()
        }
        
        # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸ (FastAPI ë¼ìš°í„°ì—ì„œ ì°¸ì¡° ê°€ëŠ¥í•˜ë„ë¡)
        VIDEO_SOURCES = self.video_sources
        yolo_model = self.yolo_model
        gmm_models = self.gmm_models
        frame_counters = self.frame_counters
        print("ì´ˆê¸°í™” ì™„ë£Œ.")


    async def process_single_stream(self, websocket: WebSocket, stream_id: str, stream_url: str):
        """ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ì˜ FFmpeg êµ¬ë™, AI ì²˜ë¦¬, ì›¹ì†Œì¼“ ì „ì†¡ íŒŒì´í”„ë¼ì¸."""
        
        command = (
            'ffmpeg -hide_banner -loglevel error '
            # ì…ë ¥/ë¶„ì„ ë²„í¼ ìµœì†Œí™”(+ ì €ì§€ì—° í”Œë˜ê·¸)
            '-fflags nobuffer -flags low_delay -avioflags direct '
            '-analyzeduration 0 -probesize 32 -fpsprobesize 0 '
            # ê¹¨ì§„ í”„ë ˆì„ì€ ì¦‰ì‹œ ë²„ë¦¼ + íƒ€ì„ìŠ¤íƒ¬í”„ ì•ˆì •í™”
            '-reconnect 1 -reconnect_streamed 1 -reconnect_delay_max 2 '
            '-http_persistent 1 '
            '-fflags +discardcorrupt '
            '-use_wallclock_as_timestamps 1 -an '
            f'-i "{stream_url}" '
            # ê°€ì¥ ë¹ ë¥¸ ìŠ¤ì¼€ì¼ëŸ¬ + FPS ì¬ìƒì„± ê¸ˆì§€(ë‚´ë¶€ ë²„í¼ë§ ë°©ì§€)
            f'-map 0:v:0 -vf "scale={OUT_W}:{OUT_H}:flags=fast_bilinear,fps=10" -vsync passthrough '
            # íŒŒì´í”„ë¡œ ì¦‰ì‹œ ë°€ì–´ë‚´ê¸° (OpenCVê°€ ë°”ë¡œ ì“°ëŠ” í¬ë§·)
            '-f image2pipe -pix_fmt bgr24 -vcodec rawvideo -'
        )
        
        process = None
        try:
            process = await asyncio.create_subprocess_exec(
                *shlex.split(command),  # ë¬¸ìì—´ì„ í† í°í™” í•¨ (command: ['ffmpeg', '-analyzeduratio', '1000000'])
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            last_yolo_boxes = [] 
            
            while True:
                frame_bytes = await process.stdout.readexactly(FRAME_SIZE)
                if not frame_bytes: break
                
                frame_bgr = np.frombuffer(frame_bytes, dtype=np.uint8).reshape(OUT_H, OUT_W, 3)
                frame = frame_bgr.copy() 
                vis = frame.copy() # ì‹œê°í™”ìš© ë³µì‚¬ë³¸

                # â­ CAMë³„ í•´ì•ˆì„  ì¢Œí‘œ ë¶ˆëŸ¬ì˜¤ê¸°
                #    - ë”•ì…”ë„ˆë¦¬ì— stream_idê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’(ê¸°ë³¸ í•´ì•ˆì„ ) ì‚¬ìš©
                cam_cfg = CAMERA_CONFIG.get(stream_id)
                safe_zone_pts = None
                safe_poly = None

                if cam_cfg:
                    safe_zone_pts = cam_cfg.get("safe_zone_px")

                # ğŸ”´ í•´ì•ˆì„ (ë¼ì¸) + í´ë¦¬ê³¤ ê·¸ë¦¬ê¸°
                if safe_zone_pts and len(safe_zone_pts) >= 2:
                    # 0, 1ë²ˆì§¸ ì ìœ¼ë¡œ í•´ì•ˆì„  ë¼ì¸
                    p1 = tuple(safe_zone_pts[0])
                    p2 = tuple(safe_zone_pts[1])

                    cv2.line(
                        vis,
                        p1,             # ì‹œì‘ì 
                        p2,             # ëì 
                        (0, 0, 255),    # ë¹¨ê°„ìƒ‰ (BGR)
                        3               # ë‘ê»˜
                    )

                    # ì „ì²´ í´ë¦¬ê³¤ (ì•ˆì „ êµ¬ì—­)
                    safe_poly = np.array(safe_zone_pts, np.int32)
                

                people_count = 0
                danger_people_count = 0
                motion_count = 0 
                fg = None 
                
                
                # -----------------------------------------------------------------------
                # 3-4. AI ì²˜ë¦¬ (YOLO + GMM ë³´ì™„ ë¡œì§)
                # -----------------------------------------------------------------------

                # â˜…ì¶”ê°€: ROI ë§ˆìŠ¤í¬ ì ìš© (fg/YOLO ì…ë ¥ì„ ê´€ì‹¬ì˜ì—­ìœ¼ë¡œ ì œí•œ)
                roi_mask = self.roi_masks.get(stream_id)
                if roi_mask is not None:
                    # ROI ì˜ì—­ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ 0ìœ¼ë¡œ ë§Œë“œëŠ” ì—°ì‚°
                    frame_for_ai = cv2.bitwise_and(frame, frame, mask=roi_mask) 
                else:
                    frame_for_ai = frame

                # ì´ë²ˆ í”„ë ˆì„ì—ì„œ YOLOê°€ íƒì§€í•œ ë°•ìŠ¤ë“¤ì„ ì €ì¥í•´ë‘ëŠ” ë¦¬ìŠ¤íŠ¸ (GMM ë³´ì™„ìš©)
                last_yolo_boxes = []

                # 1. GMM ì „ê²½ ë§ˆìŠ¤í¬ ìƒì„± (ì›€ì§ì„ í¬ì°©)
                if USE_GMM and stream_id in self.gmm_models:
                    gmm = self.gmm_models[stream_id]   # ì´ ìŠ¤íŠ¸ë¦¼ ì „ìš© GMM ëª¨ë¸ êº¼ë‚´ì˜¤ê¸°
                    # GMMìœ¼ë¡œ í˜„ì¬ í”„ë ˆì„ì—ì„œ ì›€ì§ì´ëŠ” í”½ì…€ ì˜ì—­ ì¶”ì¶œ (ì „ê²½ ë§ˆìŠ¤í¬)
                    fg = gmm.apply(frame_for_ai, learningRate=0.005)
                    # ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°(ì—´ê¸° ì—°ì‚°) í›„, ë©ì–´ë¦¬ë¥¼ í‚¤ìš°ê¸° ìœ„í•´ íŒ½ì°½(dilate)
                    fg = cv2.morphologyEx(fg, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=2)
                    fg = cv2.dilate(fg, np.ones((10, 10), np.uint8), iterations=2)

                    # ì›€ì§ì´ëŠ” í”½ì…€ ê°œìˆ˜(ë°ì€ í”½ì…€ ìˆ˜)ë¥¼ motion_countì— ì €ì¥
                    motion_count = int(cv2.countNonZero(fg))

                # 2. YOLO ì¶”ë¡  (5í”„ë ˆì„ë§ˆë‹¤ ì‹¤í–‰)
                # ì´ ìŠ¤íŠ¸ë¦¼ì˜ ì²˜ë¦¬ í”„ë ˆì„ ìˆ˜ë¥¼ 1 ì¦ê°€
                self.frame_counters[stream_id] += 1

                # DET_EVERY_FRAMES ê°„ê²©ìœ¼ë¡œ YOLO ì‹¤í–‰ (ì§€ê¸ˆì€ 1ì´ë¼ì„œ ë§¤ í”„ë ˆì„ ì‹¤í–‰)
                if self.yolo_model and self.frame_counters[stream_id] % DET_EVERY_FRAMES == 0:
                    results = self.yolo_model.predict(
                        frame_for_ai, 
                        conf=YOLO_CONF_THRESHOLD, 
                        verbose=False, 
                        classes=[0],
                        device=self.yolo_device, 
                        half=self.yolo_half,
                        imgsz=1024
                    )[0]
                    
                    for b, c in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.cls.cpu().numpy()):
                        if int(c) == 0:     # ì‚¬ëŒ í´ë˜ìŠ¤(0)ì¼ ë•Œë§Œ ì²˜ë¦¬
                            x1,y1,x2,y2 = map(int, b)
                            last_yolo_boxes.append((x1, y1, x2, y2))
                            people_count += 1

                            # ì¤‘ì‹¬ì 
                            cx = (x1 + x2) // 2
                            cy = (y1 + y2) // 2

                            # ê¸°ë³¸ì€ ì•ˆì „(ì´ˆë¡)
                            color = (0, 255, 0)

                            # âœ… í´ë¦¬ê³¤ ê¸°ì¤€ìœ¼ë¡œ ì•ˆ/ë°– íŒì •
                            if safe_poly is not None:
                                # >0: ë‚´ë¶€, =0: ê²½ê³„, <0: ì™¸ë¶€
                                inside = cv2.pointPolygonTest(safe_poly, (cx, cy), False) >= 0
                                if not inside:
                                    color = (0, 0, 255)   # í´ë¦¬ê³¤ ë°– â†’ ìœ„í—˜
                                    danger_people_count += 1


                            # YOLO íƒì§€ ë°•ìŠ¤ (ì´ˆë¡ìƒ‰)
                            cv2.rectangle(vis, (x1,y1), (x2,y2), color, 2)

                # 3. GMM ê¸°ë°˜ ì›€ì§ì„ ë³´ì™„ íƒì§€ (YOLOê°€ ë†“ì¹œ ì›€ì§ì´ëŠ” ê°ì²´ ì°¾ê¸°)
                if fg is not None:
                    contours, _ = cv2.findContours(fg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

                    for cnt in contours:
                        area = cv2.contourArea(cnt)

                        if area < MIN_MOTION_AREA or area > MAX_MOTION_AREA:
                            continue

                        x, y, w, h = cv2.boundingRect(cnt)
                        motion_box = (x, y, x + w, y + h)

                        is_covered_by_yolo = any(
                            is_overlap(motion_box, yolo_box) for yolo_box in last_yolo_boxes
                        )
                        if not is_covered_by_yolo:
                            # gpt) YOLOê°€ ëª» ì¡ì•˜ì§€ë§Œ GMMì—ì„œ ì›€ì§ì„ìœ¼ë¡œ í¬ì°©ëœ ì˜ì—­ â†’ ë…¸ë€ìƒ‰ ë°•ìŠ¤ë¡œ ë³´ì™„ í‘œì‹œ
                            cv2.rectangle(vis, (x, y), (x + w, y + h), (0, 255, 255), 2)
                            people_count += 1  # gpt) ë³´ì™„ íƒì§€ ì¸ì›ë„ people_countì— ë°˜ì˜
                
                # -----------------------------------------------------------------------
                # 3-6. ì¸ì½”ë”© ë° ì „ì†¡
                # -----------------------------------------------------------------------
                
                ok, buf = cv2.imencode(".jpg", vis, [cv2.IMWRITE_JPEG_QUALITY, 60])  # JPEG í’ˆì§ˆ
                if not ok: continue
                
                jpg_chunk = buf.tobytes()
                payload = {
                    "stream_id": stream_id, 
                    "label": cam_cfg["label"],
                    "timestamp": int(time.time() * 1000), 
                    "people": people_count, 
                    "motion": motion_count, 
                    "danger":danger_people_count
                }
                try:
                    await asyncio.wait_for(websocket.send_bytes(jpg_chunk), timeout=SEND_TIMEOUT)           # 1) JPEG í”„ë ˆì„
                    await asyncio.wait_for(websocket.send_text(json.dumps(payload)), timeout=SEND_TIMEOUT)  # 2) JSON ë©”íƒ€ë°ì´í„°
                except asyncio.TimeoutError:
                    pass  # ë§‰íˆë©´ ì´ë²ˆ í”„ë ˆì„ ë“œë¡­

        except Exception as e:
            if process:
                stderr_data = await process.stderr.read()
                print(f"[{stream_id}] Streaming Fatal Error: {e}")
                print(f"[{stream_id}] FFmpeg STDERR: {stderr_data.decode()}")
        finally:
            if process and process.returncode is None:
                process.terminate()
                await process.wait()


# ====================================================================
# â˜…â˜…â˜… 4. FastAPI ì•± ë° ë¼ìš°í„° ì„¤ì • (ë©”ì¸ ì‹¤í–‰ë¶€) â˜…â˜…â˜…
# ====================================================================

# ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
server = AIStreamServer()

# â˜…ìˆ˜ì •: lifespan ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì •ì˜ (on_event ëŒ€ì²´)
@asynccontextmanager
async def lifespan(app: FastAPI):
    # 1. ì„œë²„ ì‹œì‘(Startup) ë¡œì§: ì—¬ê¸°ì„œ initialize ë©”ì„œë“œ í˜¸ì¶œ
    await server.initialize()
    yield # ì´ ì‹œì ì—ì„œ ì„œë²„ê°€ ìš”ì²­ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
    # 2. ì„œë²„ ì¢…ë£Œ(Shutdown) ë¡œì§: í•„ìš”í•˜ë‹¤ë©´ cleanup ì½”ë“œë¥¼ ì—¬ê¸°ì— ì‘ì„±í•©ë‹ˆë‹¤.


# FastAPI ì•± ìƒì„± ì‹œ lifespan ì¸ì ì „ë‹¬
app = FastAPI(
    title="Easy AI CCTV Server", 
    version="0.1.0", 
    lifespan=lifespan # â˜…ë³€ê²½: lifespan ë“±ë¡
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"], 
    allow_headers=["*"],
)

# WebSockets ë¼ìš°í„° (í´ë˜ìŠ¤ ë©”ì„œë“œ í˜¸ì¶œë¡œ ë¡œì§ ì „ë‹¬)
@app.websocket("/ws/stream/{sid}") 
async def websocket_video_stream(websocket: WebSocket, sid: str):
    
    await websocket.accept()
    print(f"ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ WebSocket ì—°ê²° ìˆ˜ë½: {sid}")
    
    # sid -> URL ë§¤í•‘
    url_map = {
        "1": "CAM1",
        "2": "CAM2",
        "3": "CAM3",
        "4": "CAM4",
        "5": "CAM5",
        "6": "CAM6",
        "7": "CAM7",
        "8": "CAM8",
    }
    cam_id = url_map.get(sid)

    if not cam_id:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” sid: {sid}")
        await websocket.close()
        return

    cam_cfg = CAMERA_CONFIG.get(cam_id)
    if not cam_cfg:
        print(f"CAMERA_CONFIGì— {cam_id} ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        await websocket.close()
        return

    # âœ… ë‚´ë¶€ ë¡œì§ìš© ID / URL
    stream_id = cam_id          # "CAM1" ê°™ì€ ê°’ â†’ ROI/shoreline, gmm, frame_counters í‚¤ë¡œ ì‚¬ìš©
    stream_url = cam_cfg["url"] # ì‹¤ì œ m3u8 URL

    try:
        await server.process_single_stream(websocket, stream_id, stream_url)
    except Exception as e:
        print(f"ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ ì˜¤ë¥˜(sid={sid}, stream_id={stream_id}): {e}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
