from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware 
import uvicorn
import asyncio
import cv2
import time
import numpy as np 
import subprocess 
import shlex 
import json
import os
import torch
import httpx # ìŠ¤í”„ë§ api í˜¸ì¶œìš©
import math
from collections import deque # ìµœê·¼ í”„ë ˆì„ ìˆ˜ ìŠ¤ë¬´ë”©ìš©
from typing import List, Dict, Any, Tuple, Optional
from ultralytics import YOLO 
from contextlib import asynccontextmanager # â˜…ì¶”ê°€: lifespan ì‚¬ìš©ì„ ìœ„í•œ ëª¨ë“ˆ



# ====================================================================
# â˜…â˜…â˜… 0. í•µì‹¬ ì„¤ì • ë° ìƒìˆ˜ â˜…â˜…â˜…
# ====================================================================

OUT_W = 1024  # FFmpegì˜ ì¶œë ¥ í”„ë ˆì„ ë„ˆë¹„ (í”½ì…€). ë¶„ì„ ì„±ëŠ¥ê³¼ í™”ì§ˆì˜ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤.
OUT_H = 768   # FFmpegì˜ ì¶œë ¥ í”„ë ˆì„ ë†’ì´ (í”½ì…€).
YOLO_MODEL_PATH = "beach_yolo.pt" # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ/ì´ë¦„.
YOLO_CONF_THRESHOLD = 0.50   # YOLO íƒì§€ ê²°ê³¼ì˜ ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’. 0.0 ~ 1.0 ì‚¬ì´ ê°’.
DET_EVERY_FRAMES = 1 # â˜…ì„±ëŠ¥ ìµœì í™”: YOLO ì¶”ë¡ ì„ ëª‡ í”„ë ˆì„ë§ˆë‹¤ ì‹¤í–‰í• ì§€ ê²°ì •í•©ë‹ˆë‹¤. 
FRAME_SIZE = OUT_W * OUT_H * 3 # FFmpegìœ¼ë¡œë¶€í„° ì½ì–´ì˜¬ RAW BGR (3ì±„ë„) í”„ë ˆì„ì˜ ì´ ë°”ì´íŠ¸ í¬ê¸°.

MIN_STABLE_FRAMES = 6      # ëª‡ í”„ë ˆì„ í‰ê· ì„ ë³´ê³  "ì§„ì§œ ì¦ê°€"ë¼ê³  ì¸ì •í• ì§€
LOG_COOLDOWN_SEC = 3       # ê°™ì€ CAMì—ì„œ ë¡œê·¸ ì—°ì† ì „ì†¡ ìµœì†Œ ê°„ê²©(ì´ˆ)
SPRING_BASE_URL = "http://host.docker.internal:8080"  # â˜…ì—¬ê¸° ìŠ¤í”„ë§ ì„œë²„ ì£¼ì†Œ ë§ê²Œ ìˆ˜ì •í•˜ê¸°

YOUTUBE_URL_TO_FETCH = ""

MIN_MOTION_AREA = 500 # GMMì´ ì›€ì§ì„ìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ í”½ì…€ ì˜ì—­ í¬ê¸°.
MAX_MOTION_AREA = 5000

USE_GMM = False

# ì „ì—­ ìƒíƒœ ë³€ìˆ˜ (AIStreamServer í´ë˜ìŠ¤ì—ì„œ ì´ˆê¸°í™”ë¨)
VIDEO_SOURCES: List[Tuple[str, str]] = []
yolo_model = None
gmm_models = {}
frame_counters = {}

SEND_TIMEOUT = 0.08  # 80ms

CAMERA_CONFIG: Dict[str, Dict[str, Any]] = {
    "CAM1": 
    {
        "label": "ì´í˜¸í…Œìš°",
        "beachNumber": 6,
        "url": "http://211.114.96.121:1935/jejusi7/11-30T.stream/playlist.m3u8",
        "roi_px": [(0, 768), (1024, 400), (1024, 768), (0, 768)],       # yolo, gmm ê´€ì‹¬ ì˜ì—­ ì„¤ì • // ì „ì²´ í•´ìƒë„ ë³€ê²½ ì‹œ ì´ê²ƒë„ ë³€ê²½í•´ì•¼ í•¨                    # âœ³âœ³ CAM(ìŠ¤íŠ¸ë¦¼)ë³„ í•´ì•ˆì„  ì„¤ì • âœ³âœ³
        "safe_zone_px": [(0, 550), (1024, 550), (1024, 768), (0, 768),],                       
    },
    "CAM2": 
    {
        "label": "ì¤‘ë¬¸",
        "beachNumber": 2,
        "url": "http://59.8.86.94:8080/media/api/v1/hls/vurix/192871/100010/0/1/1.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],     
        "safe_zone_px": [(350, 0), (350, 768), (1024, 768), (1024, 0),],                           
    },
    "CAM3": 
    {
        "label": "í•¨ë•",
        "beachNumber": 3,
        "url": "http://211.114.96.121:1935/jejusi6/11-19.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],     
        "safe_zone_px": [(0, 510), (1024, 350), (1024, 768), (0, 768),],                       
    },
    "CAM4": 
    {
        "label": "ì›”ì •ë¦¬",
        "beachNumber": 4,
        "url": "http://211.114.96.121:1935/jejusi7/11-21.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],     
        "safe_zone_px": [(0, 290), (1024, 220), (1024, 768), (0, 768),],                         
    },
    "CAM5": 
    {
        "label": "ì• ì›” í•˜ê·€ ê°€ë¬¸ë™ í¬êµ¬",
        "beachNumber": 59,
        "url": "http://211.114.96.121:1935/jejusi6/11-15.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],      
        "safe_zone_px": [(600, 768), (500, 200), (600, 190), (1024, 700),],                        
    },
    "CAM6": 
    {
        "label": "ê¹€ë…•ë¦¬ í¬êµ¬",
        "beachNumber": 60,
        "url": "http://211.114.96.121:1935/jejusi6/11-20.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],       
        "safe_zone_px": [(100, 0), (1024, 600), (1024, 768), (0, 768),],                    
    },
    "CAM7": 
    {
        "label": "ìˆ˜ë§ˆ í¬êµ¬",
        "beachNumber": 61,
        "url": "http://211.34.191.215:1935/live/1-76.stream/playlist.m3u8",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],           
        "safe_zone_px": [(350, 768), (1024, 450), (1024, 768), (0, 768),],                   
    },
    "CAM8": 
    {
        "label": "ì‹œì—°ìš© ìœ íŠœë¸Œ ë¼ì´ë¸Œ",
        "beachNumber": 62,
        "url": "/server/test/KakaoTalk_20251118_184824700.mp4",
        "roi_px": [(0, 200), (1024, 200), (1024, 768), (0, 768)],       
        "safe_zone_px": [(900, 0), (900, 768), (1024, 0), (1024, 768),],                        
    },

}


# ====================================================================
# â˜…â˜…â˜… Helper í•¨ìˆ˜: Streamlink ë° GMM ë¡œì§ â˜…â˜…â˜…
# ====================================================================

def get_ytdlp_url(youtube_url: str) -> Optional[str]:
    """YouTube í˜ì´ì§€ì—ì„œ FFmpegì´ ë°”ë¡œ ì½ì„ m3u8 ì¬ìƒ URLë§Œ ì¶”ì¶œ."""
    try:
        # 1) m3u8 ì§ì¶œ (í•œ ì¤„ ì¶œë ¥)
        cmd = f'yt-dlp -g -f "best[protocol^=m3u8]/b[ext=m3u8]" {youtube_url}'
        out = subprocess.check_output(shlex.split(cmd), text=True, stderr=subprocess.STDOUT, timeout=20)
        url = out.strip().splitlines()[-1] if out.strip() else None
        if url and ".m3u8" in url:
            return url
    except Exception as e:
        print(f"[YTDLP] m3u8 ì§ì¶œ ì‹¤íŒ¨: {e}")

    try:
        # 2) í´ë°±: JSONì—ì„œ m3u8 í¬ë§·ë§Œ ê³¨ë¼ ì¶”ì¶œ
        cmd = f'yt-dlp --dump-json --no-warnings -f "bv*+ba/best" {youtube_url}'
        out = subprocess.check_output(shlex.split(cmd), text=True, stderr=subprocess.STDOUT, timeout=25)
        info = json.loads(out)
        for f in (info.get("formats") or []):
            u = f.get("url", "")
            if u and (".m3u8" in u or "m3u8" in (f.get("ext","") + f.get("protocol",""))):
                return u
    except Exception as e:
        print(f"[YTDLP] JSON í´ë°± ì‹¤íŒ¨: {e}")

    return None

def is_overlap(box1, box2):
    """ë‘ ë°•ìŠ¤ê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸ (GMM ë³´ì™„ íƒì§€ì—ì„œ ì¤‘ë³µ íƒì§€ ë°©ì§€ìš©)"""
    x1_min, y1_min, x1_max, y1_max = box1
    x2_min, y2_min, x2_max, y2_max = box2
    
    if (x1_max < x2_min or x1_min > x2_max or
        y1_max < y2_min or y1_min > y2_max):
        return False
    return True

def build_roi_mask_px(w:int, h:int, pts_px):
    """í”½ì…€ ë‹¤ê°í˜• pts_pxë¡œ ROI ë§ˆìŠ¤í¬ ìƒì„± (í°=ê´€ì‹¬, ê²€ì •=ë¬´ì‹œ)"""
    if not pts_px:
        return None
    m = np.zeros((h, w), np.uint8)
    cv2.fillPoly(m, [np.array(pts_px, np.int32)], 255)
    return m

# ====================================================================
# â˜…â˜…â˜… 1. AI ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ í´ë˜ìŠ¤ ì •ì˜ â˜…â˜…â˜…
# ====================================================================

class AIStreamServer:
    def __init__(self):  # ê°ì²´ ë§Œë“¤ ë•Œ ê¸°ë³¸ ë³€ìˆ˜ ì¤€ë¹„ 
        self.yolo_model = None
        self.gmm_models = {}
        self.frame_counters = {}
        self.video_sources: List[Tuple[str, str]] = []
        self.roi_masks = {}  # â˜…ì¶”ê°€: ROI ë§ˆìŠ¤í¬ ìºì‹œ

        # ğŸ”» ìœ„í—˜ ì¸ì› ìˆ˜ ìŠ¤ë¬´ë”© & ë¡œê·¸ ìƒíƒœ ê´€ë¦¬ìš©
        self.danger_histories: Dict[str, deque] = {
            cam_id: deque(maxlen=MIN_STABLE_FRAMES)
            for cam_id in CAMERA_CONFIG.keys()
        }
        self.prev_stable_danger: Dict[str, int] = {
            cam_id: 0 for cam_id in CAMERA_CONFIG.keys()
        }
        self.last_log_time: Dict[str, float] = {
            cam_id: 0.0 for cam_id in CAMERA_CONFIG.keys()
        }

    async def initialize(self): # ê¸°ë³¸ ì •ë³´ ì„¸íŒ…
        """ì„œë²„ ì‹œì‘ ì‹œ Streamlink í˜¸ì¶œ ë° ëª¨ë“  ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤."""
        global yolo_model, gmm_models, frame_counters, VIDEO_SOURCES
        
        print("ì„œë²„ ì´ˆê¸°í™” ë¡œì§ ì‹¤í–‰: Streamlink ë° ëª¨ë¸ ë¡œë“œ ì‹œì‘...")

        # stream2_youtube_url = get_ytdlp_url(YOUTUBE_URL_TO_FETCH)
        
        self.video_sources = [
            (cam_id, cfg["url"]) for cam_id, cfg in CAMERA_CONFIG.items()
        ]
        
        try:
            self.yolo_model = YOLO(os.path.join("/server/app/yolopt", YOLO_MODEL_PATH))
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.yolo_model.to(device)
            self.yolo_device = device
            self.yolo_half = (device == "cuda")
            print(f"YOLO model loaded successfully.")
        except Exception as e:
            self.yolo_model = None
            
        self.gmm_models = {} if not USE_GMM else {
            name: cv2.createBackgroundSubtractorMOG2(history=1200, varThreshold=25, detectShadows=False)
            for name, _ in self.video_sources
        }
        self.frame_counters = {cam_id: 0 for cam_id in CAMERA_CONFIG.keys()}

        # â˜…ì¶”ê°€: ROI ë§ˆìŠ¤í¬ ìƒì„± (í•´ìƒë„ ê¸°ì¤€ í•œ ë²ˆë§Œ)
        self.roi_masks = {
            cam_id: build_roi_mask_px(OUT_W, OUT_H, cfg["roi_px"])
            for cam_id, cfg in CAMERA_CONFIG.items()
        }
        
        # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸ (FastAPI ë¼ìš°í„°ì—ì„œ ì°¸ì¡° ê°€ëŠ¥í•˜ë„ë¡)
        VIDEO_SOURCES = self.video_sources
        yolo_model = self.yolo_model
        gmm_models = self.gmm_models
        frame_counters = self.frame_counters
        print("ì´ˆê¸°í™” ì™„ë£Œ.")

    async def send_danger_log(self, payload: Dict[str, Any]):
        """ìŠ¤í”„ë§ /api/cctv/addLog ë¡œ ë¹„ë™ê¸° POST"""
        url = f"{SPRING_BASE_URL}/api/cctv/addLog"
        try:
            async with httpx.AsyncClient(timeout=3.0) as client:
                resp = await client.post(url, json=payload)
                print(f"[LOG] ìŠ¤í”„ë§ ì‘ë‹µ: {resp.status_code}, {resp.text}")
        except Exception as e:
            print(f"[LOG] ìŠ¤í”„ë§ ì „ì†¡ ì‹¤íŒ¨: {e}")

    async def handle_danger_log(self, stream_id: str, danger_people_count: int):
        """
        - ìµœê·¼ MIN_STABLE_FRAMES í”„ë ˆì„ì˜ danger_people_count í‰ê· ì„ ë³´ê³ 
        - 0ì´ë©´ 0, ê·¸ ì´ìƒì´ë©´ ceil(í‰ê· ) = ì•ˆì • ì¸ì› ìˆ˜
        - ì•ˆì • ì¸ì› ìˆ˜ê°€ ì§ì „ ê°’ë³´ë‹¤ ì¦ê°€í•  ë•Œë§Œ ë¡œê·¸ ì „ì†¡
        """
        hist = self.danger_histories.get(stream_id)
        if hist is None:
            return

        # ì´ë²ˆ í”„ë ˆì„ ê°’ ì¶”ê°€
        hist.append(danger_people_count)

        # í”„ë ˆì„ì´ ì•„ì§ ì¶©ë¶„íˆ ìŒ“ì´ì§€ ì•Šì•˜ìœ¼ë©´ ìŠ¤í‚µ
        if len(hist) < MIN_STABLE_FRAMES:
            return

        avg = sum(hist) / len(hist)
        if avg == 0:
            stable_val = 0
        else:
            # 0 < avg <= 1 â†’ 1ëª…, 1 < avg <= 2 â†’ 2ëª… ...
            stable_val = math.ceil(avg)

        prev = self.prev_stable_danger.get(stream_id, 0)

        # â–¶ ì¦ê°€í•  ë•Œë§Œ ë¡œê·¸ ì „ì†¡ (0â†’1, 1â†’2, 2â†’3 ...)
        if stable_val > prev:
            now = time.time()
            last_time = self.last_log_time.get(stream_id, 0.0)

            # ë„ˆë¬´ ìì£¼ ì•ˆ ì°íˆê²Œ ì¿¨ë‹¤ìš´
            if now - last_time >= LOG_COOLDOWN_SEC:
                try:
                    # "CAM1" â†’ 1
                    cam_number = int(stream_id.replace("CAM", ""))
                except ValueError:
                    cam_number = 0

                if cam_number > 0:
                    payload = {
                        "camNumber": cam_number,
                        "dangerCount": stable_val,
                        # beachNumberëŠ” DBì—ì„œ camNumberë¡œ ì°¾ê²Œ ì„¤ê³„í–ˆìœ¼ë‹ˆê¹Œ ì•ˆ ë³´ë‚´ë„ ë¨
                    }
                    asyncio.create_task(self.send_danger_log(payload))
                    self.last_log_time[stream_id] = now
                    print(f"[{stream_id}] ğŸš¨ ìœ„í—˜êµ¬ì—­ ì¸ì› ì¦ê°€ ë¡œê·¸ ì „ì†¡: {payload}")

        # ğŸ”¥ ì¤„ì–´ë“  ê²ƒë„ ì—¬ê¸°ì„œ ë°˜ì˜ â†’ ë‹¤ìŒì— ë‹¤ì‹œ ì¦ê°€í•˜ë©´ ë˜ ì´ë²¤íŠ¸ ì¡í˜
        self.prev_stable_danger[stream_id] = stable_val


    async def process_single_stream(self, websocket: WebSocket, stream_id: str, stream_url: str):
        """ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ì˜ FFmpeg êµ¬ë™, AI ì²˜ë¦¬, ì›¹ì†Œì¼“ ì „ì†¡ íŒŒì´í”„ë¼ì¸."""
        
        is_network = stream_url.startswith(("http://", "https://", "rtmp://"))

        if is_network:
        # ğŸ‘‡ ìŠ¤íŠ¸ë¦¼ë³„ë¡œ í•„í„° ë‹¤ë¥´ê²Œ
            if stream_id in ("CAM1", "CAM2"):
                vf_filter = f"scale={OUT_W}:{OUT_H},fps=12"
            else:
                vf_filter = f"scale={OUT_W}:{OUT_H}"

            command = (
                'ffmpeg -hide_banner -loglevel error '
                f'-i "{stream_url}" '
                f'-vf "{vf_filter}" '
                '-an '
                '-f image2pipe -pix_fmt bgr24 -vcodec rawvideo -'
            )
        else:
            command = (
                'ffmpeg -hide_banner -loglevel error '
                '-re '
                f'-i "{stream_url}" '
                f'-vf "scale={OUT_W}:{OUT_H},fps=12" '
                '-vsync passthrough '
                '-an '
                '-f image2pipe -pix_fmt bgr24 -vcodec rawvideo -'
            )
        
        process = None
        try:
            process = await asyncio.create_subprocess_exec(
                *shlex.split(command),  # ë¬¸ìì—´ì„ í† í°í™” í•¨ (command: ['ffmpeg', '-analyzeduratio', '1000000'])
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            last_yolo_boxes = [] 
            
            while True:
                frame_bytes = await process.stdout.readexactly(FRAME_SIZE)
                if not frame_bytes: break
                
                frame_bgr = np.frombuffer(frame_bytes, dtype=np.uint8).reshape(OUT_H, OUT_W, 3)
                frame = frame_bgr.copy() 
                vis = frame.copy() # ì‹œê°í™”ìš© ë³µì‚¬ë³¸

                # â­ CAMë³„ í•´ì•ˆì„  ì¢Œí‘œ ë¶ˆëŸ¬ì˜¤ê¸°
                #    - ë”•ì…”ë„ˆë¦¬ì— stream_idê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’(ê¸°ë³¸ í•´ì•ˆì„ ) ì‚¬ìš©
                cam_cfg = CAMERA_CONFIG.get(stream_id)
                safe_zone_pts = None
                safe_poly = None

                if cam_cfg:
                    safe_zone_pts = cam_cfg.get("safe_zone_px")

                # ğŸ”´ í•´ì•ˆì„ (ë¼ì¸) + í´ë¦¬ê³¤ ê·¸ë¦¬ê¸°
                if safe_zone_pts and len(safe_zone_pts) >= 2:
                    # 0, 1ë²ˆì§¸ ì ìœ¼ë¡œ í•´ì•ˆì„  ë¼ì¸
                    p1 = tuple(safe_zone_pts[0])
                    p2 = tuple(safe_zone_pts[1])

                    cv2.line(
                        vis,
                        p1,             # ì‹œì‘ì 
                        p2,             # ëì 
                        (0, 0, 255),    # ë¹¨ê°„ìƒ‰ (BGR)
                        3               # ë‘ê»˜
                    )

                    # ì „ì²´ í´ë¦¬ê³¤ (ì•ˆì „ êµ¬ì—­)
                    safe_poly = np.array(safe_zone_pts, np.int32)
                

                people_count = 0
                danger_people_count = 0
                motion_count = 0 
                fg = None 
                
                
                # -----------------------------------------------------------------------
                # 3-4. AI ì²˜ë¦¬ (YOLO + GMM ë³´ì™„ ë¡œì§)
                # -----------------------------------------------------------------------

                # â˜…ì¶”ê°€: ROI ë§ˆìŠ¤í¬ ì ìš© (fg/YOLO ì…ë ¥ì„ ê´€ì‹¬ì˜ì—­ìœ¼ë¡œ ì œí•œ)
                roi_mask = self.roi_masks.get(stream_id)
                if roi_mask is not None:
                    # ROI ì˜ì—­ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ 0ìœ¼ë¡œ ë§Œë“œëŠ” ì—°ì‚°
                    frame_for_ai = cv2.bitwise_and(frame, frame, mask=roi_mask) 
                else:
                    frame_for_ai = frame

                # ì´ë²ˆ í”„ë ˆì„ì—ì„œ YOLOê°€ íƒì§€í•œ ë°•ìŠ¤ë“¤ì„ ì €ì¥í•´ë‘ëŠ” ë¦¬ìŠ¤íŠ¸ (GMM ë³´ì™„ìš©)
                last_yolo_boxes = []

                # 1. GMM ì „ê²½ ë§ˆìŠ¤í¬ ìƒì„± (ì›€ì§ì„ í¬ì°©)
                if USE_GMM and stream_id in self.gmm_models:
                    gmm = self.gmm_models[stream_id]   # ì´ ìŠ¤íŠ¸ë¦¼ ì „ìš© GMM ëª¨ë¸ êº¼ë‚´ì˜¤ê¸°
                    # GMMìœ¼ë¡œ í˜„ì¬ í”„ë ˆì„ì—ì„œ ì›€ì§ì´ëŠ” í”½ì…€ ì˜ì—­ ì¶”ì¶œ (ì „ê²½ ë§ˆìŠ¤í¬)
                    fg = gmm.apply(frame_for_ai, learningRate=0.005)
                    # ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°(ì—´ê¸° ì—°ì‚°) í›„, ë©ì–´ë¦¬ë¥¼ í‚¤ìš°ê¸° ìœ„í•´ íŒ½ì°½(dilate)
                    fg = cv2.morphologyEx(fg, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=2)
                    fg = cv2.dilate(fg, np.ones((10, 10), np.uint8), iterations=2)

                    # ì›€ì§ì´ëŠ” í”½ì…€ ê°œìˆ˜(ë°ì€ í”½ì…€ ìˆ˜)ë¥¼ motion_countì— ì €ì¥
                    motion_count = int(cv2.countNonZero(fg))

                # 2. YOLO ì¶”ë¡  (5í”„ë ˆì„ë§ˆë‹¤ ì‹¤í–‰)
                # ì´ ìŠ¤íŠ¸ë¦¼ì˜ ì²˜ë¦¬ í”„ë ˆì„ ìˆ˜ë¥¼ 1 ì¦ê°€
                self.frame_counters[stream_id] += 1

                # DET_EVERY_FRAMES ê°„ê²©ìœ¼ë¡œ YOLO ì‹¤í–‰ (ì§€ê¸ˆì€ 1ì´ë¼ì„œ ë§¤ í”„ë ˆì„ ì‹¤í–‰)
                if self.yolo_model and self.frame_counters[stream_id] % DET_EVERY_FRAMES == 0:
                    results = self.yolo_model.predict(
                        frame_for_ai, 
                        conf=YOLO_CONF_THRESHOLD, 
                        verbose=False, 
                        classes=[0],
                        device=self.yolo_device, 
                        half=self.yolo_half,
                        imgsz=1024
                    )[0]
                    
                    for b, c in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.cls.cpu().numpy()):
                        if int(c) == 0:     # ì‚¬ëŒ í´ë˜ìŠ¤(0)ì¼ ë•Œë§Œ ì²˜ë¦¬
                            x1,y1,x2,y2 = map(int, b)
                            last_yolo_boxes.append((x1, y1, x2, y2))
                            people_count += 1

                            # ì¤‘ì‹¬ì 
                            cx = (x1 + x2) // 2
                            cy = (y1 + y2) // 2

                            # ê¸°ë³¸ì€ ì•ˆì „(ì´ˆë¡)
                            color = (0, 255, 0)

                            # âœ… í´ë¦¬ê³¤ ê¸°ì¤€ìœ¼ë¡œ ì•ˆ/ë°– íŒì •
                            if safe_poly is not None:
                                # >0: ë‚´ë¶€, =0: ê²½ê³„, <0: ì™¸ë¶€
                                inside = cv2.pointPolygonTest(safe_poly, (cx, cy), False) >= 0
                                if not inside:
                                    color = (0, 0, 255)   # í´ë¦¬ê³¤ ë°– â†’ ìœ„í—˜
                                    danger_people_count += 1


                            # YOLO íƒì§€ ë°•ìŠ¤ (ì´ˆë¡ìƒ‰)
                            cv2.rectangle(vis, (x1,y1), (x2,y2), color, 2)

                    await self.handle_danger_log(stream_id, danger_people_count)

                # 3. GMM ê¸°ë°˜ ì›€ì§ì„ ë³´ì™„ íƒì§€ (YOLOê°€ ë†“ì¹œ ì›€ì§ì´ëŠ” ê°ì²´ ì°¾ê¸°)
                if fg is not None:
                    contours, _ = cv2.findContours(fg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

                    for cnt in contours:
                        area = cv2.contourArea(cnt)

                        if area < MIN_MOTION_AREA or area > MAX_MOTION_AREA:
                            continue

                        x, y, w, h = cv2.boundingRect(cnt)
                        motion_box = (x, y, x + w, y + h)

                        is_covered_by_yolo = any(
                            is_overlap(motion_box, yolo_box) for yolo_box in last_yolo_boxes
                        )
                        if not is_covered_by_yolo:
                            # gpt) YOLOê°€ ëª» ì¡ì•˜ì§€ë§Œ GMMì—ì„œ ì›€ì§ì„ìœ¼ë¡œ í¬ì°©ëœ ì˜ì—­ â†’ ë…¸ë€ìƒ‰ ë°•ìŠ¤ë¡œ ë³´ì™„ í‘œì‹œ
                            cv2.rectangle(vis, (x, y), (x + w, y + h), (0, 255, 255), 2)
                            people_count += 1  # gpt) ë³´ì™„ íƒì§€ ì¸ì›ë„ people_countì— ë°˜ì˜
                # -----------------------------------------------------------------------
                # 3-5. ë””ë²„ê·¸ìš© í˜„ì¬ ì‹œê°„ + í”„ë ˆì„ ì¹´ìš´í„° ì˜¤ë²„ë ˆì´
                # -----------------------------------------------------------------------
                now_str = time.strftime("%H:%M:%S", time.localtime())
                counter = self.frame_counters.get(stream_id, 0)

                cv2.putText(
                    vis,
                    f"{stream_id} #{counter}",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1.0,
                    (255, 255, 255),
                    2,
                    cv2.LINE_AA,
                )

                cv2.putText(
                    vis,
                    now_str,
                    (10, 70),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1.0,
                    (255, 255, 0),
                    2,
                    cv2.LINE_AA,
                )
                
                # -----------------------------------------------------------------------
                # 3-6. ì¸ì½”ë”© ë° ì „ì†¡
                # -----------------------------------------------------------------------
                
                ok, buf = cv2.imencode(".jpg", vis, [cv2.IMWRITE_JPEG_QUALITY, 60])  # JPEG í’ˆì§ˆ
                if not ok: continue
                
                jpg_chunk = buf.tobytes()
                payload = {
                    "stream_id": stream_id, 
                    "label": cam_cfg["label"],
                    "timestamp": int(time.time() * 1000), 
                    "people": people_count, 
                    "motion": motion_count, 
                    "danger":danger_people_count
                }
                try:
                    await asyncio.wait_for(websocket.send_bytes(jpg_chunk), timeout=SEND_TIMEOUT)           # 1) JPEG í”„ë ˆì„
                    await asyncio.wait_for(websocket.send_text(json.dumps(payload)), timeout=SEND_TIMEOUT)  # 2) JSON ë©”íƒ€ë°ì´í„°
                except asyncio.TimeoutError:
                    pass  # ë§‰íˆë©´ ì´ë²ˆ í”„ë ˆì„ ë“œë¡­

        except Exception as e:
            if process:
                stderr_data = await process.stderr.read()
                print(f"[{stream_id}] Streaming Fatal Error: {e}")
                print(f"[{stream_id}] FFmpeg STDERR: {stderr_data.decode()}")
        finally:
            if process and process.returncode is None:
                process.terminate()
                await process.wait()


# ====================================================================
# â˜…â˜…â˜… 4. FastAPI ì•± ë° ë¼ìš°í„° ì„¤ì • (ë©”ì¸ ì‹¤í–‰ë¶€) â˜…â˜…â˜…
# ====================================================================

# ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
server = AIStreamServer()

# â˜…ìˆ˜ì •: lifespan ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì •ì˜ (on_event ëŒ€ì²´)
@asynccontextmanager
async def lifespan(app: FastAPI):
    # 1. ì„œë²„ ì‹œì‘(Startup) ë¡œì§: ì—¬ê¸°ì„œ initialize ë©”ì„œë“œ í˜¸ì¶œ
    await server.initialize()
    yield # ì´ ì‹œì ì—ì„œ ì„œë²„ê°€ ìš”ì²­ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
    # 2. ì„œë²„ ì¢…ë£Œ(Shutdown) ë¡œì§: í•„ìš”í•˜ë‹¤ë©´ cleanup ì½”ë“œë¥¼ ì—¬ê¸°ì— ì‘ì„±í•©ë‹ˆë‹¤.


# FastAPI ì•± ìƒì„± ì‹œ lifespan ì¸ì ì „ë‹¬
app = FastAPI(
    title="Easy AI CCTV Server", 
    version="0.1.0", 
    lifespan=lifespan # â˜…ë³€ê²½: lifespan ë“±ë¡
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"], 
    allow_headers=["*"],
)

# WebSockets ë¼ìš°í„° (í´ë˜ìŠ¤ ë©”ì„œë“œ í˜¸ì¶œë¡œ ë¡œì§ ì „ë‹¬)
@app.websocket("/ws/stream/{sid}") 
async def websocket_video_stream(websocket: WebSocket, sid: str):
    
    await websocket.accept()
    print(f"ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ WebSocket ì—°ê²° ìˆ˜ë½: {sid}")
    
    # sid -> URL ë§¤í•‘
    url_map = {
        "1": "CAM1",
        "2": "CAM2",
        "3": "CAM3",
        "4": "CAM4",
        "5": "CAM5",
        "6": "CAM6",
        "7": "CAM7",
        "8": "CAM8",
    }
    cam_id = url_map.get(sid)

    if not cam_id:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” sid: {sid}")
        await websocket.close()
        return

    cam_cfg = CAMERA_CONFIG.get(cam_id)
    if not cam_cfg:
        print(f"CAMERA_CONFIGì— {cam_id} ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        await websocket.close()
        return

    # âœ… ë‚´ë¶€ ë¡œì§ìš© ID / URL
    stream_id = cam_id          # "CAM1" ê°™ì€ ê°’ â†’ ROI/shoreline, gmm, frame_counters í‚¤ë¡œ ì‚¬ìš©
    stream_url = cam_cfg["url"] # ì‹¤ì œ m3u8 URL

    try:
        await server.process_single_stream(websocket, stream_id, stream_url)
    except Exception as e:
        print(f"ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ ì˜¤ë¥˜(sid={sid}, stream_id={stream_id}): {e}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
